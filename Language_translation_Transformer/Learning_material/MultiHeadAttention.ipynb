{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['म', 'ह', 'ा', 'न']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"महान\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "batch_size  = 30\n",
    "num_heads = 8\n",
    "emb_dim = 512\n",
    "token_inp = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(batch_size,token_inp,emb_dim)\n",
    "data.size()\n",
    "B,T,C=data.size() #B:Batch len, T:number Token, C:dimension of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 50, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_linear = nn.Linear(in_features=emb_dim,out_features=3*emb_dim)\n",
    "out_linear = nn.Linear(in_features=emb_dim,out_features=emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 1536])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = input_linear(data)\n",
    "new.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = input_linear(data).split(emb_dim,dim=-1)\n",
    "q,k,v = qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q.view(B,T,num_heads,C//num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 8, 64])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 8, 50, 64])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q.transpose(1,2) # or q = q.permute(0,2,1,3)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.view(B,T,num_heads,C//num_heads).transpose(1,2)\n",
    "v = v.view(B,T,num_heads,C//num_heads).permute(0,2,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 8, 50, 64]),\n",
       " torch.Size([30, 8, 50, 64]),\n",
       " torch.Size([30, 8, 50, 64]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape,k.shape,v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention for multiple heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single head:\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhoik\\AppData\\Local\\Temp\\ipykernel_16416\\1508428625.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  scalar_product = F.softmax((q@k.transpose(-2,-1))/ math.sqrt(d_k))\n"
     ]
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scalar_product = F.softmax((q@k.transpose(-2,-1))/ math.sqrt(d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 8, 50, 64]),\n",
       " torch.Size([30, 8, 64, 50]),\n",
       " torch.Size([30, 8, 50, 50]),\n",
       " torch.Size([30, 8, 50, 64]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, k.transpose(-2,-1).shape,scalar_product.shape,v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention = scalar_product@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 8, 50, 64])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = ((q@k.transpose(-2,-1))/ math.sqrt(d_k))\n",
    "mask = torch.triu(torch.full(scaled.size(),float('-inf')),diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1086,  0.0241,  0.0190,  0.0170,  0.0250,  0.1070, -0.0152,  0.0375,\n",
       "          0.0707,  0.0511,  0.1340, -0.0173,  0.0381,  0.0345,  0.0416,  0.0333,\n",
       "          0.0140,  0.0426,  0.1132, -0.0325,  0.0618,  0.0323,  0.0649,  0.0240,\n",
       "          0.0122,  0.0853,  0.0192,  0.0625,  0.0602, -0.0682,  0.0943,  0.0454,\n",
       "          0.0668,  0.0624,  0.0006,  0.0155,  0.1139,  0.1363,  0.0148, -0.0051,\n",
       "          0.1329, -0.0170,  0.0492, -0.0213, -0.0133, -0.0218, -0.0062,  0.1501,\n",
       "         -0.0045,  0.0240], grad_fn=<SelectBackward0>),\n",
       " tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "         [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled[0][0][1],mask[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention_masked = F.softmax((scaled+mask),dim=-1)@v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 8, 50, 64]),\n",
       " tensor([[ 0.5031,  0.3435, -0.1777,  ..., -0.5685,  0.1213,  0.3096],\n",
       "         [ 0.3170,  0.2586, -0.3077,  ..., -0.4127,  0.2261,  0.1800],\n",
       "         [ 0.3054,  0.0597, -0.4125,  ..., -0.4866,  0.2588,  0.1979],\n",
       "         ...,\n",
       "         [ 0.2566,  0.1146, -0.4509,  ..., -0.4326,  0.0508,  0.1586],\n",
       "         [ 0.2589,  0.1135, -0.4532,  ..., -0.4314,  0.0588,  0.1593],\n",
       "         [ 0.2608,  0.1130, -0.4591,  ..., -0.4315,  0.0578,  0.1530]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention_masked.shape,self_attention_masked[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossProduct(q,k,v,mask=None):\n",
    "    print(f\"{q.shape}{k.transpose(-2,-1).shape}{v.shape}\")\n",
    "    d_k = q.size()[-1]\n",
    "    scalar = (q@k.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = torch.full(scalar.size(),float('-inf'))\n",
    "        mask = torch.triu(mask)\n",
    "        scalar += mask\n",
    "    attention = F.softmax(scalar,dim=-1)@v\n",
    "    return attention\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 8, 50, 64])torch.Size([30, 8, 64, 50])torch.Size([30, 8, 50, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 8, 50, 64])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = CrossProduct(q,k,v)\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 8, 64])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = num.transpose(1,2)\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 50, 512)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 50, 512])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# num = num.reshape(B,T,num_heads*C)\n",
    "num = num.contiguous().view(B,T,C)\n",
    "num.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,emb_dim,num_heads):\n",
    "        super().__init__()\n",
    "        # self.data = data\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads  = num_heads\n",
    "        assert self.emb_dim%self.num_heads==0\n",
    "        self.input_linear = nn.Linear(in_features=self.emb_dim,out_features=3*self.emb_dim)\n",
    "        self.output_linear = nn.Linear(in_features=self.emb_dim,out_features=self.emb_dim)\n",
    "\n",
    "    def forward(self,data):\n",
    "        self.data = data\n",
    "        B,T,C = self.data.size() \n",
    "        q,k,v = self.input_linear(self.data).split(self.emb_dim,dim=-1) # in--> 30,50,512 out-->30,50,1536\n",
    "        q = q.view(B,T,self.num_heads,C//self.num_heads).transpose(1,2)\n",
    "        k = k.view(B,T,self.num_heads,C//self.num_heads).transpose(1,2)\n",
    "        v = v.view(B,T,self.num_heads,C//self.num_heads).transpose(1,2)\n",
    "        attention = CrossProduct(q,k,v)\n",
    "        attention = attention.transpose(1,2).contiguous().view(B,T,C)\n",
    "        out = out_linear(attention)\n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = MultiHeadAttention(emb_dim=emb_dim,num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 8, 50, 64])torch.Size([30, 8, 64, 50])torch.Size([30, 8, 50, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 50, 512]),\n",
       " tensor([-2.5665e-01,  4.0416e-02,  8.0793e-02,  5.0079e-02, -1.8421e-03,\n",
       "          1.9777e-01, -2.4611e-01, -2.7946e-01, -3.6623e-01,  3.4265e-02,\n",
       "          1.8036e-02,  1.0174e-01, -4.3216e-02,  3.7045e-02, -1.9604e-01,\n",
       "          8.1235e-02, -1.2366e-01,  8.8899e-02,  2.6143e-01,  1.0775e-01,\n",
       "          4.2346e-02, -1.8797e-02, -3.0577e-02,  2.9665e-01, -5.0877e-02,\n",
       "         -4.3885e-02,  9.9424e-02,  1.0587e-01, -1.5881e-01, -1.1248e-01,\n",
       "          4.3572e-02,  1.6446e-01, -2.4672e-01,  9.6683e-02, -1.5970e-01,\n",
       "         -2.2575e-01,  5.0873e-02, -1.3085e-01, -8.2951e-03,  2.4432e-01,\n",
       "         -1.9944e-01,  3.3726e-02,  1.0078e-01,  7.7097e-02,  1.0899e-01,\n",
       "         -7.3702e-03, -3.9956e-02, -9.7962e-02, -6.9033e-02,  7.4464e-02,\n",
       "         -1.7607e-01, -3.1354e-02, -1.5993e-01,  2.7830e-01,  2.6122e-01,\n",
       "         -8.6033e-02,  6.3355e-02, -8.3642e-02, -1.0748e-02, -1.0637e-01,\n",
       "         -1.6083e-01,  3.9753e-01,  3.5859e-01,  1.7571e-01, -2.7137e-01,\n",
       "         -2.4756e-03,  3.1062e-01, -3.8944e-01,  1.9510e-02,  3.7104e-01,\n",
       "          1.0932e-01, -2.0516e-02,  1.7407e-01,  2.5559e-01, -1.7441e-01,\n",
       "         -2.9880e-02, -3.3244e-02, -2.1314e-01,  5.3712e-02,  1.1170e-01,\n",
       "          1.8368e-01, -3.2460e-01, -1.3179e-01,  2.7143e-01, -2.4233e-01,\n",
       "         -9.7223e-02,  4.2825e-02,  1.5525e-01, -5.9683e-02,  2.5737e-01,\n",
       "          5.7816e-02, -2.6134e-01, -5.9867e-02, -1.3850e-01, -1.6513e-01,\n",
       "          1.4244e-01,  2.6903e-01,  2.3709e-01,  1.3122e-01,  1.0564e-02,\n",
       "         -1.8556e-01,  2.6832e-01,  7.8728e-02, -4.9289e-02, -2.3180e-01,\n",
       "         -1.9298e-01, -3.3986e-02, -1.4097e-01, -6.8034e-02, -2.6069e-01,\n",
       "         -1.9631e-01,  9.8551e-02, -2.7830e-01,  1.9334e-02,  1.7387e-01,\n",
       "          1.8137e-03, -1.7696e-01, -1.2506e-02,  3.1192e-01,  1.7408e-01,\n",
       "          9.3196e-02,  2.4166e-02,  1.5645e-01, -2.2385e-01,  6.8581e-02,\n",
       "         -1.5152e-01, -9.0316e-02, -4.9025e-01,  2.9948e-01, -1.0267e-01,\n",
       "         -2.3893e-01,  1.0874e-01,  3.9105e-02,  2.8759e-02,  1.7877e-01,\n",
       "         -8.3103e-03, -4.0428e-01, -5.4428e-02,  4.5928e-01,  1.2471e-01,\n",
       "          1.1170e-02,  1.2888e-01,  7.2060e-02, -1.5000e-01, -1.1883e-01,\n",
       "         -2.6292e-01, -1.0933e-01, -2.5455e-01,  3.3519e-02,  2.1995e-01,\n",
       "          6.1764e-02,  9.6641e-02,  9.2325e-03,  8.2416e-02, -2.3614e-01,\n",
       "          1.4166e-01, -4.2934e-02, -9.7565e-02,  1.3347e-01,  2.8142e-01,\n",
       "         -2.2166e-01, -1.4373e-01, -7.8880e-02, -2.4376e-01, -1.0881e-01,\n",
       "         -3.2421e-02,  2.1687e-02,  2.3583e-01,  1.4825e-01, -4.9150e-03,\n",
       "          2.3408e-01,  1.2456e-01,  2.4847e-01,  2.1433e-01,  4.8141e-02,\n",
       "         -2.2974e-01,  8.6394e-02,  3.8798e-02,  2.5363e-01, -6.4989e-02,\n",
       "          1.6331e-01,  5.2572e-02, -3.4948e-01,  2.4105e-01, -8.8516e-02,\n",
       "          4.1105e-01, -8.4055e-02,  5.2004e-02,  6.7262e-03,  1.4183e-01,\n",
       "         -1.8139e-01, -1.7200e-02, -2.0388e-02,  2.2804e-02,  2.5857e-01,\n",
       "         -7.1417e-02,  8.0362e-02, -6.8826e-02,  5.3128e-02,  6.5256e-02,\n",
       "          1.0547e-01,  1.7534e-01, -1.2404e-01,  1.6670e-02, -7.2313e-02,\n",
       "          8.2115e-02, -2.9057e-01, -3.5233e-02, -1.9869e-01, -1.2433e-01,\n",
       "         -6.5939e-02,  1.8037e-01,  1.0967e-01,  2.3647e-01, -4.2012e-02,\n",
       "         -3.6851e-01, -9.8075e-02,  2.6934e-02, -8.4233e-02,  2.2866e-01,\n",
       "         -1.5638e-01,  2.4554e-01, -1.9712e-01, -7.6522e-02,  1.8159e-01,\n",
       "          3.5164e-02, -5.6176e-02, -1.9538e-01, -8.3528e-02,  9.0207e-02,\n",
       "          7.1204e-02, -2.5522e-01,  3.7891e-01, -1.6075e-01, -1.4007e-01,\n",
       "          5.6022e-02, -4.2923e-02,  1.7496e-01, -2.4130e-01,  1.4097e-01,\n",
       "         -2.1771e-01,  2.2083e-01,  1.6275e-01, -1.1960e-01,  1.4779e-01,\n",
       "          9.8518e-02, -7.0550e-02,  5.5403e-02,  2.4524e-01,  1.0099e-01,\n",
       "          3.1970e-01, -2.0869e-01, -2.2534e-01,  1.1282e-01,  8.7250e-02,\n",
       "         -4.9178e-02,  2.6949e-01, -8.7181e-02, -4.6139e-02,  3.4955e-02,\n",
       "          1.7054e-01,  1.7755e-01,  2.6683e-01,  1.9640e-01,  1.4769e-01,\n",
       "         -1.0359e-01, -3.4959e-02, -1.2931e-01, -1.2091e-03, -9.4750e-02,\n",
       "         -1.7666e-01, -3.6866e-02,  5.4068e-03,  2.8402e-02,  3.9741e-02,\n",
       "          5.3617e-02,  2.3688e-01,  8.9078e-02,  1.1246e-01, -1.8882e-01,\n",
       "          2.6809e-01, -1.9654e-01, -7.0069e-02,  7.2816e-02,  5.4712e-02,\n",
       "          2.9973e-01,  3.2190e-01,  1.4630e-01, -1.0775e-01,  4.0420e-01,\n",
       "         -1.4706e-01,  1.2630e-01, -7.0583e-02, -1.4193e-01, -4.1382e-03,\n",
       "         -1.1849e-01, -1.1289e-01, -4.7826e-02, -1.3261e-01, -2.3272e-01,\n",
       "          1.4389e-01,  2.0606e-01,  1.9314e-01,  2.8995e-01, -1.1829e-01,\n",
       "         -1.6868e-02, -7.5900e-03, -1.2678e-03, -8.4335e-02,  3.3623e-01,\n",
       "          1.5481e-01,  2.2709e-01, -1.3040e-02,  3.3538e-01, -1.5053e-02,\n",
       "         -6.4214e-02, -4.7224e-02,  1.3279e-01,  6.3208e-02, -5.3692e-02,\n",
       "          6.3396e-02,  2.3780e-01, -2.9981e-01,  2.5351e-01,  3.2851e-01,\n",
       "          6.8049e-03,  6.3919e-02,  3.8824e-01,  1.8104e-01, -2.5559e-01,\n",
       "         -3.2577e-02,  1.8607e-02,  6.8552e-02,  2.5995e-02,  1.5626e-01,\n",
       "          3.1295e-01, -5.5763e-02, -1.1495e-02, -6.5465e-02,  1.7139e-01,\n",
       "         -1.3496e-01,  5.0653e-02, -2.5077e-01, -7.6944e-02, -1.0079e-01,\n",
       "         -9.7273e-02,  5.8087e-02, -1.2095e-02,  2.1837e-01, -1.2205e-01,\n",
       "         -4.4839e-02,  2.2597e-01,  1.6005e-01, -1.7715e-02,  1.4358e-01,\n",
       "         -1.4223e-01,  7.8617e-02, -1.1188e-01,  3.8041e-02,  2.4430e-02,\n",
       "         -1.5467e-01,  1.3028e-01, -1.1501e-02, -9.1270e-02,  2.4484e-02,\n",
       "         -4.1871e-01,  3.1766e-01, -1.1550e-02, -8.7284e-03, -3.8898e-01,\n",
       "         -4.7048e-02, -1.2992e-01,  2.1574e-01, -2.7377e-01, -8.6372e-02,\n",
       "         -1.2314e-01,  1.7636e-01, -2.6566e-02,  7.3379e-03,  2.9288e-02,\n",
       "         -8.0427e-02,  1.5991e-02, -6.8218e-02, -1.0537e-01, -3.5102e-02,\n",
       "          3.1195e-01,  2.5189e-02,  3.2295e-01,  3.0014e-01, -1.0822e-01,\n",
       "         -1.3217e-02, -4.4344e-02, -2.6881e-02, -5.5771e-03, -4.6956e-02,\n",
       "          1.7211e-02,  2.2294e-02,  1.3858e-01, -7.1263e-02, -3.6386e-01,\n",
       "          3.6181e-01, -2.5254e-01, -1.2740e-01, -7.8981e-02,  1.7177e-01,\n",
       "          9.7995e-02,  1.2807e-02, -8.7209e-02, -9.6863e-02, -8.7107e-03,\n",
       "         -9.8800e-02,  1.5829e-01,  1.8409e-01,  1.2682e-01, -7.4049e-02,\n",
       "          2.8169e-01,  9.4110e-02,  8.5418e-02,  3.2307e-03,  4.5223e-02,\n",
       "         -1.6117e-02, -2.1250e-01,  2.6720e-01, -1.4811e-01,  6.2867e-02,\n",
       "         -3.1167e-04,  1.0658e-01,  4.7126e-01, -2.3480e-02, -3.3705e-01,\n",
       "          2.1106e-02, -1.9649e-01, -5.8575e-01,  3.0999e-01, -1.1737e-01,\n",
       "          1.1952e-02,  6.5933e-02, -1.7508e-01, -3.3090e-02, -2.2282e-01,\n",
       "          1.9257e-01, -4.0585e-01, -6.7481e-02, -1.8812e-02,  2.2470e-01,\n",
       "         -2.7579e-01,  1.5301e-01, -1.7627e-01, -1.9277e-01, -1.7996e-01,\n",
       "          1.9296e-02,  1.5651e-01,  4.6243e-02,  1.6424e-01,  3.7994e-02,\n",
       "          3.2139e-01, -6.1840e-02, -2.1296e-02,  1.5702e-01,  4.3828e-02,\n",
       "         -7.9714e-02,  1.5694e-01, -5.9811e-02, -3.5555e-01, -5.8684e-02,\n",
       "          3.0375e-01, -5.6014e-02, -2.5447e-02,  2.8624e-01,  2.5594e-01,\n",
       "         -2.4329e-01,  2.3745e-01,  8.7740e-02,  1.3843e-01,  1.4170e-01,\n",
       "         -5.8634e-02,  1.6550e-01,  5.3306e-02, -4.0471e-01, -9.7502e-02,\n",
       "         -4.2029e-02, -1.0478e-01, -7.6447e-03, -4.0925e-01, -3.1738e-02,\n",
       "          8.1495e-02,  1.3701e-01,  2.0334e-01,  2.1652e-01,  1.2415e-03,\n",
       "         -2.2615e-01,  8.0497e-02,  8.9194e-02, -5.2893e-02,  1.6261e-01,\n",
       "         -1.1939e-01, -9.8595e-02,  6.0657e-02,  3.3177e-02, -2.0017e-01,\n",
       "          6.3479e-02,  1.7715e-01,  3.6976e-02,  1.8755e-01, -2.5996e-02,\n",
       "          4.5184e-02,  2.6067e-01,  2.8942e-01, -2.1635e-01, -1.8569e-01,\n",
       "         -1.6810e-01,  1.7886e-01], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb=number.forward(data)\n",
    "numb.shape,numb[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (input_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
       "  (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
