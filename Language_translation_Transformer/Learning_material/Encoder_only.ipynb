{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "batch_size = 30   # Each batch will contain 30 sentences\n",
    "max_sequence_len = 200  # max sentence len will be 200\n",
    "d_model = 512 # Dimensionality of each char in sequence i.e 200 x 512\n",
    "number_heads = 8  # Number of attention heads\n",
    "fnn_hidden = 2048 # Feedforward layer dim\n",
    "drop_prob = 0.1 # Dropout \n",
    "num_layer = 5 #number of layers  of encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameteresConfig():\n",
    "    def __init__(self,**kwargs):\n",
    "        self.batch_size = 30 # batch_size\n",
    "        self.max_sequence_len = 200 # max_sequence_len\n",
    "        self.d_model = 512 # d_model\n",
    "        self.num_heads = 8 # number_heads\n",
    "        self.fnn_hidden = 2048 #fnn_hidden\n",
    "        self.drop_prob = 0.1 # drop_prob\n",
    "        self.num_layer = 5 #num_layer\n",
    "\n",
    "        #override the default arguments\n",
    "        for key,val in kwargs.items():\n",
    "            setattr(self,key,val)\n",
    "\n",
    "    def display(self):\n",
    "        print(\"parameters are:\")\n",
    "        for key,val in vars(self).items():\n",
    "            print(f\"{key} = {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ParameteresConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters are:\n",
      "batch_size = 30\n",
      "max_sequence_len = 200\n",
      "d_model = 512\n",
      "num_heads = 8\n",
      "fnn_hidden = 2048\n",
      "drop_prob = 0.1\n",
      "num_layer = 5\n"
     ]
    }
   ],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = torch.rand(30,200,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalarproduct(q,k,v,mask=False):\n",
    "    d_k = q.size()[-1]\n",
    "    dot_prod = (q @ k.transpose(-1,-2)) / math.sqrt(d_k)\n",
    "    print(f\"size of dot_pod of q and k: {dot_prod.size()}\")\n",
    "    if mask:\n",
    "        print(f\"Shape of mask in: {mask.size()}\")\n",
    "        #Adding the mask \n",
    "        dot_prod += mask\n",
    "    soft = F.softmax(dot_prod,dim=-1)\n",
    "    out = soft @ v \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        assert config.d_model % config.num_heads ==0\n",
    "        self.head_dim = config.d_model/config.num_heads\n",
    "        self.num_head = config.num_heads\n",
    "        self.d_model = config.d_model\n",
    "        self.in_linear = nn.Linear(self.d_model,3*self.d_model)\n",
    "        self.out_linear = nn.Linear(self.d_model,self.d_model)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        B,T,C = x.size() #--> batch_size,max_sequence_len,d_model i.e embeddings\n",
    "        print(x.shape)\n",
    "        q,k,v = self.in_linear(x).split(self.d_model,dim=-1)\n",
    "        print(f\"Before --> q.shape:{q.shape}, k.shape:{k.shape}, v.shape: {v.shape}\")\n",
    "        q = q.view(B,T,self.num_head,C//self.num_head).transpose(1,2)\n",
    "        k = k.view(B,T,self.num_head,C//self.num_head).transpose(1,2)\n",
    "        v = v.view(B,T,self.num_head,C//self.num_head).transpose(1,2)\n",
    "        print(f\"Before --> q.shape:{q.shape}, k.shape:{k.shape}, v.shape: {v.shape}\")\n",
    "        attention = scalarproduct(q,k,v)\n",
    "        print(f\"Dot product shape: {attention.shape}\")\n",
    "        attention = attention.transpose(1,2).reshape(B,T,C)\n",
    "        out = self.out_linear(attention)\n",
    "        print(f\"final Output shape: {out.shape}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi = MultiHeadAttention(config)\n",
    "# new = multi.forward(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,config,elp=1e-5):\n",
    "        super().__init__()\n",
    "        self.parameter_size = config.d_model\n",
    "        self.elp = elp\n",
    "        self.gamma = nn.Parameter(torch.ones(self.parameter_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.parameter_size))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        print(f\"Mean ({mean.size()})\")\n",
    "        var = ((x-mean)**2).mean(dim=-1,keepdim=True)\n",
    "        print(f\"varience size: {var.shape}\")\n",
    "        std = (var+self.elp).sqrt()\n",
    "        print(f\"Standard Deviation  ({std.size()})\")\n",
    "        y = (x-var)/std\n",
    "        print(f\"Y size: {y.size()}\")\n",
    "        out = y*self.gamma + self.beta\n",
    "        print(f\"self.gamma: {self.gamma.size()}, self.beta: {self.beta.size()}\")\n",
    "        print(f\"out: {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LayerNormalization(nn.Module):\n",
    "#     def __init__(self,config,epl=1e-5):\n",
    "#         super().__init__()\n",
    "#         self.epl = epl\n",
    "#         self.gamma = nn.Parameter(torch.ones(config.d_model))\n",
    "#         self.beta = nn.Parameter(torch.zeros(config.d_model))\n",
    "#     def forward(self,x):\n",
    "#         out = F.layer_norm(x,self.gamma.shape,self.gamma,self.beta,self.epl)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_norm = LayerNormalization(config)\n",
    "# new =layer_norm.forward(sen)\n",
    "# new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters are:\n",
      "batch_size = 30\n",
      "max_sequence_len = 200\n",
      "d_model = 512\n",
      "num_heads = 8\n",
      "fnn_hidden = 2048\n",
      "drop_prob = 0.1\n",
      "num_layer = 5\n"
     ]
    }
   ],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.in_linear = nn.Linear(config.d_model,config.fnn_hidden)\n",
    "        self.out_linear = nn.Linear(config.fnn_hidden,config.d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(config.drop_prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x =  self.in_linear(x)\n",
    "        print(f\"input after first linear layer: {x.shape}\")\n",
    "        x = self.relu(x)\n",
    "        print(f\"input after relu: {x.shape}\")\n",
    "        x = self.dropout(x)\n",
    "        print(f\"input after dropout: {x.shape}\")\n",
    "        x = self.out_linear(x)\n",
    "        print(f\"input after last linear layer: {x.shape}\")\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1934e-02,  8.6727e-02, -1.1665e-01,  ..., -1.0056e-01,\n",
       "          -8.2042e-02, -7.0911e-02],\n",
       "         [ 2.7607e-02, -1.2417e-01, -9.7045e-02,  ..., -1.0569e-01,\n",
       "           1.2329e-01,  9.2798e-02],\n",
       "         [-2.0217e-02,  6.9337e-02, -1.9854e-01,  ..., -1.0679e-01,\n",
       "           1.1816e-01,  2.0627e-01],\n",
       "         ...,\n",
       "         [ 9.6069e-02, -1.1769e-01,  7.1897e-02,  ..., -2.3883e-01,\n",
       "          -3.7176e-02,  5.6822e-02],\n",
       "         [ 6.9802e-02, -8.7005e-02, -8.0719e-02,  ..., -2.8943e-02,\n",
       "           5.8761e-02,  1.3279e-01],\n",
       "         [ 1.7715e-01,  5.4293e-02, -8.7211e-02,  ...,  2.2315e-03,\n",
       "           1.4968e-01,  3.1983e-03]],\n",
       "\n",
       "        [[-5.6912e-02, -6.6315e-02, -2.0896e-01,  ..., -2.6100e-02,\n",
       "           9.3751e-02, -1.0334e-01],\n",
       "         [-5.5294e-02,  7.8071e-02, -9.2510e-02,  ..., -5.6710e-02,\n",
       "           1.1387e-01,  4.6866e-02],\n",
       "         [ 4.1873e-02,  4.3941e-02, -1.2474e-01,  ..., -1.5462e-01,\n",
       "          -7.8897e-03,  1.2410e-01],\n",
       "         ...,\n",
       "         [ 2.7240e-02, -8.6956e-02, -2.0120e-01,  ..., -1.1571e-01,\n",
       "           9.9857e-02, -1.4461e-01],\n",
       "         [ 9.6716e-02, -7.9593e-02, -4.7924e-03,  ..., -1.0357e-01,\n",
       "           1.1753e-01,  2.0952e-01],\n",
       "         [ 4.6225e-02, -1.0043e-01, -1.0906e-02,  ..., -9.5252e-02,\n",
       "           4.2045e-02, -2.4362e-03]],\n",
       "\n",
       "        [[ 1.2244e-02,  4.2806e-02, -1.2747e-01,  ..., -2.4728e-01,\n",
       "           5.3396e-02, -1.0321e-02],\n",
       "         [ 6.7558e-02, -6.5270e-02, -3.2473e-02,  ..., -8.4820e-02,\n",
       "          -6.1428e-02,  1.8582e-01],\n",
       "         [ 1.3168e-01,  4.3570e-02, -1.5664e-01,  ...,  6.7660e-02,\n",
       "           1.3594e-01, -1.1140e-02],\n",
       "         ...,\n",
       "         [ 3.0343e-02,  4.8338e-02, -2.0157e-01,  ..., -1.7097e-01,\n",
       "           4.0739e-02,  1.6836e-01],\n",
       "         [-7.8255e-03,  2.3864e-02, -1.4850e-01,  ..., -1.4590e-01,\n",
       "           7.0149e-02,  2.1133e-01],\n",
       "         [-6.5601e-02,  3.9484e-02, -1.7578e-01,  ..., -5.5351e-02,\n",
       "          -6.3096e-03,  9.5966e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.3050e-02,  3.3297e-02, -6.8236e-02,  ..., -2.0805e-01,\n",
       "           1.0766e-01, -7.2891e-02],\n",
       "         [ 1.2448e-01,  7.5632e-02, -9.0215e-02,  ..., -6.1957e-02,\n",
       "           6.8226e-02,  8.8444e-02],\n",
       "         [ 4.2741e-02, -5.4939e-02,  6.0314e-03,  ..., -5.8178e-03,\n",
       "           2.0375e-01,  1.1341e-01],\n",
       "         ...,\n",
       "         [ 1.5065e-01,  7.1776e-02, -2.7978e-02,  ..., -1.2953e-01,\n",
       "           4.7792e-02,  8.2121e-02],\n",
       "         [ 2.4108e-03,  1.8956e-02, -1.6733e-01,  ..., -1.3549e-01,\n",
       "           2.2091e-01,  5.6556e-02],\n",
       "         [ 7.5977e-02, -1.8355e-02, -1.6776e-01,  ..., -5.3281e-02,\n",
       "           1.7923e-01, -4.6582e-03]],\n",
       "\n",
       "        [[ 5.2035e-02,  9.4680e-02, -1.6350e-01,  ...,  6.8309e-02,\n",
       "           1.5319e-01,  4.5378e-04],\n",
       "         [ 5.4426e-02, -7.9035e-02, -7.6856e-02,  ..., -7.7646e-02,\n",
       "          -4.0132e-02,  3.7356e-02],\n",
       "         [ 4.0896e-02, -2.7679e-06, -1.9149e-01,  ..., -1.3067e-01,\n",
       "           1.2487e-01, -3.9964e-02],\n",
       "         ...,\n",
       "         [ 4.7539e-02,  2.9914e-02, -1.7607e-01,  ..., -3.6043e-01,\n",
       "           1.0699e-01,  9.5931e-02],\n",
       "         [-7.0836e-02,  6.8696e-02, -7.9216e-02,  ..., -1.4005e-01,\n",
       "           4.9575e-02,  2.9344e-02],\n",
       "         [-1.7900e-03, -5.2395e-02, -5.9242e-02,  ..., -5.3903e-02,\n",
       "           7.2476e-02,  1.0875e-02]],\n",
       "\n",
       "        [[ 1.2191e-01, -1.0058e-01, -4.2311e-02,  ..., -4.4564e-02,\n",
       "           6.2485e-02, -5.6306e-02],\n",
       "         [-3.9812e-03, -6.3714e-02,  1.0573e-02,  ..., -2.2456e-01,\n",
       "           1.8114e-01,  1.5856e-01],\n",
       "         [ 3.9135e-02, -7.4152e-02, -1.0022e-01,  ..., -3.8853e-02,\n",
       "          -2.8348e-02, -1.1265e-02],\n",
       "         ...,\n",
       "         [-8.6203e-02, -7.1395e-03, -5.4863e-02,  ..., -3.2160e-02,\n",
       "           8.7392e-02,  4.9973e-02],\n",
       "         [ 9.9178e-02,  6.0340e-02, -1.5785e-01,  ..., -8.5082e-02,\n",
       "           2.4785e-01, -2.6526e-02],\n",
       "         [ 7.7830e-02, -1.1555e-01, -5.7561e-03,  ..., -1.2946e-01,\n",
       "           1.3054e-01,  8.0479e-02]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_fnn = PositionwiseFeedForward(config)\n",
    "pos_fnn(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters are:\n",
      "batch_size = 30\n",
      "max_sequence_len = 200\n",
      "d_model = 512\n",
      "num_heads = 8\n",
      "fnn_hidden = 2048\n",
      "drop_prob = 0.1\n",
      "num_layer = 5\n"
     ]
    }
   ],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.layernorm1 = LayerNormalization(config)\n",
    "        self.dropout1 = nn.Dropout(config.drop_prob)\n",
    "        self.pos_fnn = PositionwiseFeedForward(config)\n",
    "        self.layernorm2 = LayerNormalization(config)\n",
    "        self.dropout2 = nn.Dropout(config.drop_prob)\n",
    "\n",
    "    def forward(self,x):\n",
    "        residule_x = x\n",
    "        print(\"-----------------ATTENTION------------------\")\n",
    "        x = self.attention(x)\n",
    "        print(\"-----------------DROPOUT 1-------------------\")\n",
    "        x = self.dropout1(x)\n",
    "        print(f\"After dropout shape: {x.shape}\")\n",
    "        print(\"-----------------ADD & LAYER NORMALIZATION 1-------------------\")\n",
    "        x = self.layernorm1(x+residule_x)\n",
    "        residule_x = x\n",
    "        print(\"-----------------FEED FORWARD NETWORK-------------------\")\n",
    "        x = self.pos_fnn(x)\n",
    "        print(\"-----------------DROPOUT 2-------------------\")\n",
    "        x = self.dropout2(x)\n",
    "        print(f\"After dropout shape: {x.shape}\")\n",
    "        print(\"-----------------ADD & LAYER NORMALIZATOIN 2-------------------\")\n",
    "        x = self.layernorm2(x+residule_x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n"
     ]
    }
   ],
   "source": [
    "Enc_layer = EncoderLayer(config)\n",
    "Enc_layer(sen);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(*[EncoderLayer(config) for _ in range(config.num_layer)])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------ATTENTION------------------\n",
      "torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 200, 512]), k.shape:torch.Size([30, 200, 512]), v.shape: torch.Size([30, 200, 512])\n",
      "Before --> q.shape:torch.Size([30, 8, 200, 64]), k.shape:torch.Size([30, 8, 200, 64]), v.shape: torch.Size([30, 8, 200, 64])\n",
      "size of dot_pod of q and k: torch.Size([30, 8, 200, 200])\n",
      "Dot product shape: torch.Size([30, 8, 200, 64])\n",
      "final Output shape: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 1-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATION 1-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n",
      "-----------------FEED FORWARD NETWORK-------------------\n",
      "input after first linear layer: torch.Size([30, 200, 2048])\n",
      "input after relu: torch.Size([30, 200, 2048])\n",
      "input after dropout: torch.Size([30, 200, 2048])\n",
      "input after last linear layer: torch.Size([30, 200, 512])\n",
      "-----------------DROPOUT 2-------------------\n",
      "After dropout shape: torch.Size([30, 200, 512])\n",
      "-----------------ADD & LAYER NORMALIZATOIN 2-------------------\n",
      "Mean (torch.Size([30, 200, 1]))\n",
      "varience size: torch.Size([30, 200, 1])\n",
      "Standard Deviation  (torch.Size([30, 200, 1]))\n",
      "Y size: torch.Size([30, 200, 512])\n",
      "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
      "out: torch.Size([30, 200, 512])\n"
     ]
    }
   ],
   "source": [
    "encod = Encoder(config)\n",
    "final_encoder_output = encod(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
